\section{Schätzer}

Wir treffen folgende Annahmen:
\begin{itemize}
	\item Parameterraum \(\Theta \subset \R^m\)
	\item Familie von Wahrscheinlichkeitsmassen \((\P_\theta)_{\theta \in \Theta}\) auf \((\Omega, \F)\); 
    für jedes Element im Parameterraum existiert ein Modell / Wahrscheinlichkeitsraum $(\Omega, \F, \P_{\theta})$.
	\item Zufallsvariablen \(X_1, \ldots, X_n\) auf \((\Omega, \F)\)
\end{itemize}
Wir nennen die Gesamtheit der beobachteten Daten \(x_1, \ldots, x_n\) (wobei $x_i = X_i(\omega)$) und die ZV \(X_1, \ldots, X_n\) Stichprobe.
\begin{mainbox}{Definition Schätzer}
	Ein Schätzer ist eine Zufallsvariable \(T: \Omega \mapsto \R\) von der Form
	\[T = t(X_1, \ldots, X_n), \quad t: \R^n \mapsto \R\]
\end{mainbox}
Ein Schätzer \(T\) ist \textbf{erwartungstreu}, falls für alle \(\theta \in \Theta\) gilt:
\[\E_\theta [T] = \theta\]
Sei \(\theta \in \Theta\) und \(T\) ein Schätzer. Der \textbf{Bias} (erwartete Schätzfehler) von \(T\) im Modell \(\P_\theta\) ist definiert als:
\[\E_\theta[T]-\theta\]
Der mittlere quadratische Schätzfehler (MSE) von \(T\) im Modell \(\P_\theta\) ist definiert als:
\begin{align*}
	\text{MSE}_\theta[T] & = \E_\theta[(T-\theta)^2]                    \\
	\text{MSE}_\theta[T] & = \Var_\theta(T) + (\E_\theta[T] - \theta)^2
\end{align*}

\subsection{Maximum-Likelihood-Methode}
\subsubsection{Likelihood-Funktion, ML-Schätzer}
Die Likelihood-Funktion ist definiert als
\[L(x_1, \ldots, x_n; \theta) = \begin{cases}
		p(x_1, \ldots, x_n; \theta) & \text{(diskret)} \\
		f(x_1, \ldots, x_n; \theta) & \text{(stetig)}
	\end{cases} \]

\noindent Für jedes \(x_1, \ldots, x_n \in W\) sei \(t_{ML}(x_1, \ldots, x_n)\) der Wert, welcher die Funktion \(\Theta \mapsto L(x_1, \ldots, x_n; \theta)\) maximiert. Ein Maximum-Likelihood-Schätzer ist dann definiert als
\[T_{ML} = t_{ML}(X_1, \ldots, X_n)\]

\subsubsection{Anwendung der Methode}
Die Maximum-Likelihood-Methode ist ein Weg, um systematisch einen Schätzer zu bestimmen.
\begin{enumerate}
	\item Gemeinsame Dichte/Verteilung der ZV finden
	\item Bestimme davon die Log-Likelihood-Funktion\\ \(f(\theta) := \ln(L(x_1, \ldots, x_n;\theta))\)
	\item \(f(\theta)\) nach \(\theta\) ableiten
	\item Nullstelle von \(f'(\theta)\) finden
	\item $f''(\theta) < 0$ oder anderes Argument, dass wir das Maximum gefunden haben (evtl. Randstellen überprüfen!).
\end{enumerate}

\tbf{Beispielrechnung mit Randstelle:}\\
Wir betrachten den Parameterraum $\Theta = \R_+ \times R_+$ mit $\theta = (\theta_1, \theta_2)$ und die Modellfamilie $(\P_\theta)_{\theta\in \Theta}$, wobei die ZV $X_1, \ldots, X_n$ iid. mit $f_{\theta_1, \theta_2}(x) = \begin{cases}
    \theta_2e^{\theta_1\theta_2 - \theta_2x} & \text{falls }x \geq \theta_1,\\
    0 & \text{sonst.}
\end{cases}$

Bestimme den ML-Schätzer für $\theta = (\theta_1, \theta_2)$:

Die Likelihood-Funktion ist 
\begin{align*}
    L(x_1, \dots, x_n; \theta_1, \theta_2) &= \prod_{i = 1}^{n}f_{\theta_1, \theta_2}(x_i) = \prod_{i = 1}^n \theta_2e^{\theta_1\theta_2 - \theta_2 x_i} \mathds{1}_{x_i \in [\theta_1, \infty)}\\
    &= \theta_2^n \exp\left(n\theta_1\theta_2 - \theta_2 \sum_{i=1}^n x_i\right) \prod_{i=1}^n \mathds{1}_{x_i \in [\theta_1, \infty)}\\
    &= \theta_2^n \exp\left(n\theta_1\theta_2 - \theta_2 \sum_{i=1}^n x_i\right) \mathds{1}_{\min(x_i) \geq \theta_1}
\end{align*}
Wenn wir davon jetzt die Log-Likelihood Funktion nehmen würden, und diese ableiten, kommen wir auf etwas undefiniertes. 
Das liegt daran, dass sobald $\theta_1 > \min(x_i)$ gibt es einen Sprung zu $0$.

Da $\theta_2 > 0$ folgt 
\begin{align*}
    L(x_1, ..., x_n; \theta_1, \theta_2) > 0 \iff \forall i \in \{1, \dots, n\}: x_i \geq \theta_1
\end{align*}
Um $L(x_1, ..., x_n; \theta_1, \theta_2)$ zu maximieren, schränken wir den Ursprungsraum mit $\theta_1 \leq \min_{1 \leq i \leq n}(x_i)$ ein 
und bestimmen die Log-Likelihood Funktion als
$$f(\theta_1, \theta_2) = \log\left(L(x_1, ..., x_n; \theta_1, \theta_2)\right) = n \log(\theta_2) + n \theta_1\theta_2 - \theta_2 \sum_{i = 1}^n x_i$$
Da $\theta_2 > 0$ ist (unter der Einschränkung) die Log-Likelihood Funktion für $\theta_1 = \min_{1 \leq i \leq n}(x_i)$ maximal (unabhängig von $\theta_2$).
Somit können wir $\theta_1$ so fixieren und $\log(L)$ separat nach $\theta_2$ maximieren. 
\begin{align*}
    \frac{\delta f}{\delta \theta_2} = \frac{n}{\theta_2} + n\theta_1 - \sum_{i = 1}^n x_i&= 0\\
    n\theta_1 - \sum_{i = 1}^n x_i&= -\frac{n}{\theta_2}\\
    \theta_2 &= \frac{n}{\sum_{i = 1}^n x_i - n \theta_1}
\end{align*}
Überprüfen des kritischen Punktes:
\begin{align*}
     \frac{\delta^2}{\delta^2\theta_2^2}f\left(\theta_1, \frac{n}{\sum_{i = 1}^n x_i - n\theta_1}\right) &= -\frac{n}{\frac{n}{\left(\sum_{i = 1}^n x_i - n\theta_1\right)^2}}\\
     = -\left(\sum_{i = 1}^n x_i - n \theta_1\right)^2 &< 0
\end{align*}
Daraus erhalten wir die Maximimum-Likelihood-Schätzer für $\theta_1$ und $\theta_2$:
\begin{align*}
    T_1 = \min_{1\leq i \leq n}X_i \text{ und } T_2 = \frac{n}{\sum_{i=1}^n X_i - nT_1}
\end{align*}

